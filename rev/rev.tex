\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\usepackage{microtype}
\usepackage{geometry}
\geometry{margin=1in}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}

\begin{document}

\begin{center}
    \LARGE\textbf{Combined Reviewer Reports}\\[6pt]
    \large Manuscript: \textit{Physics-Informed Neural Networks for Beam Deflection Analysis: Methodology and Applications}\\
    \normalsize Ref. No.: SA-2025-445
\end{center}

\vspace{12pt}

\section*{Reviewer 1 -- Public Reviewer Report (Ref No. SA-2025-445)}

\subsection*{Major comments (actionable)}
\begin{enumerate}
    \item \textbf{Boundary-condition transform: scope \& proof.}\\
    The hard constraint $x(1-x)$ enforces $w(0)=w(L)=0$, but the text also claims exact satisfaction for fourth-order systems. Please clarify what is enforced exactly: displacement only, or slope/moment/shear as well? Provide derivations/examples for mixed BCs (e.g., clamped-free, clamped-pinned). If the method targets only Dirichlet displacement BCs, state limits explicitly.
    
    \item \textbf{Adaptive weighting ablation.}\\
    Support the scheduler $W_{BC}(t)=10e^{-0.0001t}$ with ablation: constant vs. exponential, different initial weights/decays, and report sensitivity. Normalize loss terms (e.g., by BC/PDE residual magnitudes) to ensure the schedule is not just rescaling.
    
    \item \textbf{Gaussian regularization for point load.}\\
    You cite rules for $\sigma$ (function of $L$ and collocation density $N_c$) but then fix $\sigma=0.01L$. Provide a systematic study of $\sigma$: error vs.\ $\sigma$, and how it affects recovering the expected jump in shear/continuity in $w^{(3)}$. Report moment/shear fields and verify jump conditions at $x=L/2$.
    
    \item \textbf{Quantitative evaluation \& fairness of baselines.}\\
    Provide tables of relative $L_2$ error and BC max violation for all cases, not only a single point-load. Compare against: (a) classical FEM with multiple mesh sizes; (b) a soft-constraint PINN; (c) a PINN with Fourier features/RAS as cited. Include wall-clock time and hardware; "5x speedup" needs evidence and precise conditions.
    
    \item \textbf{Convergence claims vs. solution accuracy.}\\
    Training loss values (e.g., $\mathcal{O}(10^{-10})$) do not necessarily reflect solution error. Plot validation error vs.\ iterations and show early-stopping behavior.
    
    \item \textbf{Reproducibility package.}\\
    Report multiple random seeds with mean~$\pm$~std to demonstrate robustness. List all hyperparameters (depth/width, activation, optimizer, LR schedule, batch/collocation sizes, BC point sampling, PDE residual weighting, L-BFGS settings, gradient clipping, random seeds). Provide exact material/geometry parameters used (E, I, P, q, L, units) and the non-dimensionalization if any. If code is shared, ensure it's anonymized for double-blind review (the current GitHub mention would break anonymity).
    
    \item \textbf{Higher-order derivatives \& smoothness.}\\
    Since Euler--Bernoulli uses $w^{(4)}$, discuss numerical stability of AD on deep networks and whether Sobolev training/gradient regularization or swish vs.\ tanh materially changes higher-order derivative quality.
\end{enumerate}

\subsection*{Summary}
The manuscript proposes three PINN enhancements for Euler--Bernoulli beam deflection problems:
\begin{enumerate}
    \item a hard-constrained output transform $w_\theta(x)=x(1-x)\,\mathrm{NN}(x)$ to enforce fixed-end Dirichlet BCs;
    \item an exponentially-decaying boundary-loss weight $W_{BC}(t)=10e^{-0.0001t}$; and
    \item a Gaussian regularization of Dirac delta point loads with $\sigma=0.01L$.
\end{enumerate}
Results are shown for cantilever, fully restrained, and mid-span point-loaded beams, with training curves and brief accuracy claims.

\subsection*{Recommendation}
Major Revision

\vspace{12pt}
\hrule
\vspace{12pt}

\section*{Reviewer 2 -- Confidential Review Report}

\subsection*{Overall Summary and Recommendation}
This manuscript presents a well-structured and technically sound study on the application of Physics-Informed Neural Networks (PINNs) to Euler--Bernoulli beam deflection problems. The authors introduce three clear methodological innovations: a hard-constraint formulation, an adaptive weighting scheme, and a Gaussian-regularized Dirac delta for point loads. The paper is well-organized, with a logical flow from literature review to methodology, application, and discussion. The novelty is evident and substantiated by the specific technical contributions. The work is validated on standard beam configurations with impressive accuracy.

While the manuscript is strong, several points require clarification and expansion to improve its impact, reproducibility, and scope. My recommendation is \textbf{Major Revision}. The detailed comments below are intended to help the authors strengthen the paper before final publication.

\subsection*{General Questions for the Authors}
\begin{enumerate}[label=Q\arabic*.]
    \item \textbf{Novelty and Comparative Assessment:} The claim of a 37\% convergence improvement via adaptive weightingâ€”how was this quantified? Was it based on a direct comparison with a static weighting scheme under identical conditions (network architecture, optimizer, initializations)? Please provide more details or a side-by-side comparison figure/table.
    
    \item \textbf{Implementation Details and Reproducibility:}
    \begin{itemize}
        \item The GitHub link provided in the Limitations section appears to be broken. Please ensure the code is publicly available and the link is correct for the sake of reproducibility.
        \item What was the exact number and spatial distribution of collocation points ($N_c$) for each case? Was uniform random sampling used, or a different strategy?
    \end{itemize}
    
    \item \textbf{Error Analysis and Validation:}
    \begin{itemize}
        \item Why is the relative $L_2$ error for the point load case (0.56\%) higher than the 0.30\% reported by Zhang et al.\ (2020)? Does this indicate a limitation of the Gaussian regularization approach compared to other singularity-handling methods?
        \item Was the Maximum Absolute Error computed for all cases? It is only reported in the comparative Table 6. Presenting it for all case studies would provide a more complete picture of solution accuracy.
    \end{itemize}
    
    \item \textbf{Parameter Selection and Sensitivity:}
    \begin{itemize}
        \item Was a systematic sensitivity analysis performed on key hyperparameters, such as the Gaussian bandwidth ($\sigma$), the decay rate in $W_{BC}(t)$, or the network depth/width? The choice of $\sigma=0.01L$ is stated as optimal, but the process for determining this should be explained (e.g., via a brief parametric study).
        \item \textbf{Material Property:} The material properties are defined only via the composite parameter $EI$. Please clarify: What specific material is being modeled? (e.g., structural steel with $E=200$ GPa, or a generic material?). This is crucial for readers to contextualize the physical scale of the deflections and the value of $EI=200\ \mathrm{N\cdot m^2}$ used in the point load example, which seems unusually low for real-world beams (suggesting a lab-scale or normalized example).
    \end{itemize}
    
    \item \textbf{Scalability and Generalizability:}
    \begin{itemize}
        \item Has the proposed framework been tested on more complex boundary conditions (e.g., multi-span beams, springs) or time-dependent loads?
        \item What are the anticipated primary challenges in extending this 1D methodology to 2D plate or 3D solid mechanics problems, beyond those mentioned in the limitations?
    \end{itemize}
    
    \item \textbf{Convergence Analysis:}
    \begin{itemize}
        \item Was the identified three-phase convergence pattern (boundary fitting, physics compliance, fine-tuning) consistent across all three benchmark problems? Can this behavior be justified analytically or linked to the properties of the optimizer?
    \end{itemize}
    
    \item \textbf{Comparison with Classical Methods:}
    \begin{itemize}
        \item Beyond setup time, was a direct comparison of computational runtime and memory usage performed between the proposed PINN and a standard FEM solver (e.g., Abaqus or FEniCS) for an equivalent level of accuracy?
    \end{itemize}
\end{enumerate}

\subsection*{Specific Comments and Minor Revisions}

\subsubsection*{Strengths}
\begin{itemize}
    \item The paper is exceptionally well-organized. The structure is logical, moving seamlessly from a comprehensive literature review to a clear methodology, detailed applications, and a thoughtful discussion of limitations.
    \item The novelty is significant and well-articulated. The combination of hard constraints for fourth-order systems, a time-decaying adaptive weight, and an optimized Gaussian regularizer for point loads constitutes a genuine contribution to the field.
    \item The use of a hybrid optimizer (Adam + L-BFGS) is a good practice that leverages the strengths of both algorithms.
    \item The inclusion of a detailed limitations section is commendable and adds credibility.
\end{itemize}

\subsubsection*{Weaknesses and Suggestions for Improvement}
\begin{description}
    \item[W1. Reproducibility:] The broken GitHub link is a major issue. This must be fixed. Furthermore, the manuscript would benefit from a dedicated ``Code and Data Availability'' section in the Declarations.
    
    \item[W2. Parameter Justification:] The choice of many hyperparameters (e.g., network width, initial weight of 10 in $W_{BC}(t)$, the constant $9\times10^{-14}$ in the point-load loss) appears heuristic. A short discussion or a reference to a tuning process (even in the supplementary material) would be very helpful.
    
    \item[W3. Clarity and Typos:]
    \begin{itemize}
        \item Check for consistent citation commands (e.g., mix of `\texttt{citep}', `\texttt{@citet}').
        \item Ensure all figures and tables referenced in the text (e.g., Figure 1, Table 2) are included in the submission package. The LaTeX code provided references files like \texttt{fig.png} and \texttt{cantilever\_results.png} which were not part of the uploaded content.
        \item Abstract: ``Physics-Inforned'' should be ``Physics-Informed.''
    \end{itemize}
    
    \item[Material Specification:] As raised in Q4, explicitly state the material being modeled. For example: ``In this study, we model a linearly elastic material with a generic flexural rigidity $EI$. The value of $EI=200\ \mathrm{N\cdot m^2}$ used in Problem 3 corresponds to a lab-scale specimen for demonstration purposes.'' This clarifies the assumptions for the reader.
\end{description}

\subsection*{Final Recommendation}
This is a solid and valuable contribution to the application of PINNs in computational mechanics. The methodological innovations are clear, the validation is thorough for the chosen cases, and the writing is generally clear. Addressing the points raised aboveâ€”particularly regarding reproducibility, parameter sensitivity, and material specificationâ€”will significantly enhance the manuscript's quality, clarity, and impact.

\textbf{Decision: Major Revision}

\vspace{12pt}
\hrule
\vspace{12pt}

\section*{Combined Editor/Actionable Items Suggested to Authors}
\begin{enumerate}
    \item Clarify the exact scope of the hard-constrained transform (which BC components are enforced exactly) and provide derivations/examples for mixed BCs.
    \item Perform ablation studies for the adaptive weighting schedule and provide normalized-loss experiments.
    \item Provide a parametric study on Gaussian regularization $\sigma$ and report its effect on shear/moment jump recovery.
    \item Expand quantitative comparisons: relative $L_2$ errors, BC max violations, multiple baselines (FEM, soft-PINN, Fourier/RAS PINN), runtime and hardware.
    \item Plot validation error vs.\ iterations, show early-stopping behavior, and report multiple random-seed statistics.
    \item Provide a complete reproducibility section: all hyperparameters, exact geometry/material values (or clarifying normalization), collocation strategies, and a corrected anonymized code link.
    \item Discuss higher-order derivative stability (AD), possible remedies (Sobolev-training, gradient regularization), and sensitivity to activation functions.
\end{enumerate}

\vfill

\end{document}
